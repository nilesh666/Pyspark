{"cells": [{"cell_type": "code", "execution_count": 1, "id": "224c7c23-e9e4-4d62-a7f2-cfae5c280d52", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Found 4 items\ndrwxr-xr-x   - root hadoop          0 2025-09-01 04:29 /data\ndrwxrwxrwt   - hdfs hadoop          0 2025-08-31 05:40 /tmp\ndrwxrwxrwt   - hdfs hadoop          0 2025-08-31 04:29 /user\ndrwxrwxrwt   - hdfs hadoop          0 2025-08-31 04:21 /var\n"}], "source": "!hadoop fs -ls /"}, {"cell_type": "code", "execution_count": 2, "id": "a714c79d-b4fa-4b4f-830c-2e808fe4f8be", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Found 1 items\n-rw-r--r--   2 root hadoop    1048576 2025-09-01 04:29 /data/customers.csv\n"}], "source": "!hadoop fs -ls /data"}, {"cell_type": "code", "execution_count": 3, "id": "452ee8be-92cd-4b62-9421-9334fff56ed4", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Found 3 items\n-rw-r--r--   2 nileshnandan_ts hadoop    1060750 2025-08-31 05:38 /tmp/customers1mb.csv\ndrwxrwxrwt   - hdfs            hadoop          0 2025-08-31 04:21 /tmp/hadoop-yarn\ndrwx-wx-wx   - hive            hadoop          0 2025-08-31 04:22 /tmp/hive\n"}], "source": "!hadoop fs -ls /tmp"}, {"cell_type": "code", "execution_count": 6, "id": "256de4d5-420c-4448-a3d5-f16ebe67c248", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "customer_id,name,city,state,country,registration_date,is_active\n0,Customer_0,Pune,Maharashtra,India,2023-06-29,False\n1,Customer_1,Bangalore,Tamil Nadu,India,2023-12-07,True\n2,Customer_2,Hyderabad,Gujarat,India,2023-10-27,True\n3,Customer_3,Bangalore,Karnataka,India,2023-10-17,False\n4,Customer_4,Ahmedabad,Karnataka,India,2023-03-14,False\n5,Customer_5,Hyderabad,Karnataka,India,2023-07-28,False\n6,Customer_6,Pune,Delhi,India,2023-08-29,False\n7,Customer_7,Ahmedabad,West Bengal,India,2023-12-28,True\n8,Customer_8,Pune,Karnataka,India,2023-06-22,True\n9,Customer_9,Mumbai,Telangana,India,2023-01-05,True\n10,Customer_10,Pune,Gujarat,India,2023-08-05,True\n11,Customer_11,Delhi,West Bengal,India,2023-08-02,False\n12,Customer_12,Chennai,Gujarat,India,2023-11-21,False\n13,Customer_13,Chennai,Karnataka,India,2023-11-06,True\n14,Customer_14,Hyderabad,Tamil Nadu,India,2023-02-07,False\n15,Customer_15,Mumbai,Gujarat,India,2023-03-02,True\n16,Customer_16,Chennai,Karnataka,India,2023-04-05,False\n17,Customer_17,Hyderabad,West Bengal,India"}], "source": "!hadoop fs -head /tmp/customers1mb.csv"}, {"cell_type": "code", "execution_count": 4, "id": "f6aaf760-4c24-4a8c-9241-d8f9bbace1db", "metadata": {"tags": []}, "outputs": [{"data": {"text/html": "\n            <div>\n                <p><b>SparkSession - hive</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://cluster-e5bc-m.us-central1-a.c.my-ml-ai-data-project-95524.internal:39033\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.5.3</code></dd>\n              <dt>Master</dt>\n                <dd><code>yarn</code></dd>\n              <dt>AppName</dt>\n                <dd><code>PySparkShell</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        ", "text/plain": "<pyspark.sql.session.SparkSession at 0x7f3cbebf83d0>"}, "execution_count": 4, "metadata": {}, "output_type": "execute_result"}], "source": "spark"}, {"cell_type": "code", "execution_count": 5, "id": "1e8859e8-3b9a-4afd-a328-1b96b2c3f5d7", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "25/09/01 12:20:29 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"}], "source": "from pyspark.sql import SparkSession\n\nspark = SparkSession.builder \\\n.appName(\"DF\")\\\n.getOrCreate()"}, {"cell_type": "code", "execution_count": 7, "id": "02e562f8-5eba-45c8-8711-d6d285de0688", "metadata": {"tags": []}, "outputs": [], "source": "# df = spark.read\\\n# .format('csv')\\\n# .option('header','true')\\\n# .option('inferSchema', 'true')\\\n# .option('mode', \"{}\") FAILFAST, PERMISSIVE(DEFAULT), DROPMALFORMED\n# .load('/tmp/customers1mb.csv')\n#infer schema is heavy and sometimes might be wrong instead use StructType\n\nfrom pyspark.sql.types import StructType, StructField, IntegerType, FloatType, BooleanType, StringType\n\nschema = StructType([\n    StructField('customer_id', IntegerType(), False),\n    StructField('name', StringType(), False),\n    StructField('city', StringType(), False),\n    StructField('state',StringType(),False),\n    StructField('country', StringType(), False),\n    StructField('registration_date', StringType(), False),\n    StructField('is_active', BooleanType(), False)\n])\n\n#Dont leave the columns and also this can be done as a DDL command"}, {"cell_type": "code", "execution_count": 8, "id": "bb862c43-b90e-4a7e-85e2-523bcde281c4", "metadata": {"tags": []}, "outputs": [], "source": "df = spark.read\\\n.format('csv')\\\n.option('header','true')\\\n.schema(schema)\\\n.load('/tmp/customers1mb.csv')"}, {"cell_type": "code", "execution_count": 9, "id": "789f9c77-9953-4169-a8ea-bfb3f85e7b83", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- customer_id: integer (nullable = true)\n |-- name: string (nullable = true)\n |-- city: string (nullable = true)\n |-- state: string (nullable = true)\n |-- country: string (nullable = true)\n |-- registration_date: string (nullable = true)\n |-- is_active: boolean (nullable = true)\n\n"}], "source": "df.printSchema()"}, {"cell_type": "code", "execution_count": 11, "id": "7059d0da-d651-4628-97bc-61ed5dc668ed", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "+-----------+-----------+---------+-----------+-------+-----------------+---------+\n|customer_id|       name|     city|      state|country|registration_date|is_active|\n+-----------+-----------+---------+-----------+-------+-----------------+---------+\n|          0| Customer_0|     Pune|Maharashtra|  India|       2023-06-29|    false|\n|          1| Customer_1|Bangalore| Tamil Nadu|  India|       2023-12-07|     true|\n|          2| Customer_2|Hyderabad|    Gujarat|  India|       2023-10-27|     true|\n|          3| Customer_3|Bangalore|  Karnataka|  India|       2023-10-17|    false|\n|          4| Customer_4|Ahmedabad|  Karnataka|  India|       2023-03-14|    false|\n|          5| Customer_5|Hyderabad|  Karnataka|  India|       2023-07-28|    false|\n|          6| Customer_6|     Pune|      Delhi|  India|       2023-08-29|    false|\n|          7| Customer_7|Ahmedabad|West Bengal|  India|       2023-12-28|     true|\n|          8| Customer_8|     Pune|  Karnataka|  India|       2023-06-22|     true|\n|          9| Customer_9|   Mumbai|  Telangana|  India|       2023-01-05|     true|\n|         10|Customer_10|     Pune|    Gujarat|  India|       2023-08-05|     true|\n|         11|Customer_11|    Delhi|West Bengal|  India|       2023-08-02|    false|\n|         12|Customer_12|  Chennai|    Gujarat|  India|       2023-11-21|    false|\n|         13|Customer_13|  Chennai|  Karnataka|  India|       2023-11-06|     true|\n|         14|Customer_14|Hyderabad| Tamil Nadu|  India|       2023-02-07|    false|\n|         15|Customer_15|   Mumbai|    Gujarat|  India|       2023-03-02|     true|\n|         16|Customer_16|  Chennai|  Karnataka|  India|       2023-04-05|    false|\n|         17|Customer_17|Hyderabad|West Bengal|  India|       2023-08-21|    false|\n|         18|Customer_18|     Pune|      Delhi|  India|       2023-10-04|     true|\n|         19|Customer_19|  Kolkata|    Gujarat|  India|       2023-02-05|     true|\n+-----------+-----------+---------+-----------+-------+-----------------+---------+\nonly showing top 20 rows\n\n"}], "source": "df.show()"}, {"cell_type": "code", "execution_count": 12, "id": "2e1f7c72-a0ad-47f3-8bd1-616de9b115a5", "metadata": {"tags": []}, "outputs": [{"data": {"text/plain": "['customer_id',\n 'name',\n 'city',\n 'state',\n 'country',\n 'registration_date',\n 'is_active']"}, "execution_count": 12, "metadata": {}, "output_type": "execute_result"}], "source": "df.columns"}, {"cell_type": "code", "execution_count": 13, "id": "922b55fc-60d8-4da6-9ff9-84cd9197836b", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "25/09/01 13:18:26 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n[Stage 1:>                                                          (0 + 1) / 1]\r"}, {"name": "stdout", "output_type": "stream", "text": "+-------+-----------------+-------------+---------+-----------+-------+-----------------+\n|summary|      customer_id|         name|     city|      state|country|registration_date|\n+-------+-----------------+-------------+---------+-----------+-------+-----------------+\n|  count|            17653|        17653|    17653|      17653|  17653|            17653|\n|   mean|           8826.0|         NULL|     NULL|       NULL|   NULL|             NULL|\n| stddev|5096.126486525493|         NULL|     NULL|       NULL|   NULL|             NULL|\n|    min|                0|   Customer_0|Ahmedabad|      Delhi|  India|       2023-01-01|\n|    max|            17652|Customer_9999|     Pune|West Bengal|  India|       2023-12-31|\n+-------+-----------------+-------------+---------+-----------+-------+-----------------+\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "df.describe().show()"}, {"cell_type": "code", "execution_count": 14, "id": "369d8c25-061c-496c-bdc3-5bd48039c33a", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+----------+---------+\n|      name|     city|\n+----------+---------+\n|Customer_0|     Pune|\n|Customer_1|Bangalore|\n|Customer_2|Hyderabad|\n+----------+---------+\nonly showing top 3 rows\n\n"}], "source": "df.select('name','city').show(3)"}, {"cell_type": "code", "execution_count": 16, "id": "f11a083f-4c6b-4dea-b9c0-764b34fd2e0d", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+-----------+----------+----+-----------+-------+-----------------+---------+\n|customer_id|      name|city|      state|country|registration_date|is_active|\n+-----------+----------+----+-----------+-------+-----------------+---------+\n|          0|Customer_0|Pune|Maharashtra|  India|       2023-06-29|    false|\n|          6|Customer_6|Pune|      Delhi|  India|       2023-08-29|    false|\n|          8|Customer_8|Pune|  Karnataka|  India|       2023-06-22|     true|\n+-----------+----------+----+-----------+-------+-----------------+---------+\nonly showing top 3 rows\n\n"}], "source": "df.filter(df.city=='Pune').show(3)"}, {"cell_type": "code", "execution_count": 17, "id": "fc819081-453b-4377-8a4e-68ade08035b8", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+-----------+-----------+-----+-----+-------+-----------------+---------+\n|customer_id|       name| city|state|country|registration_date|is_active|\n+-----------+-----------+-----+-----+-------+-----------------+---------+\n|          6| Customer_6| Pune|Delhi|  India|       2023-08-29|    false|\n|         18|Customer_18| Pune|Delhi|  India|       2023-10-04|     true|\n|         26|Customer_26|Delhi|Delhi|  India|       2023-03-22|     true|\n+-----------+-----------+-----+-----+-------+-----------------+---------+\nonly showing top 3 rows\n\n"}], "source": "df.where(df.state=='Delhi').show(3)"}, {"cell_type": "code", "execution_count": 18, "id": "9b6440d1-69a0-4144-aa30-ccb9edf2c75f", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+-----------+\n|      state|\n+-----------+\n|    Gujarat|\n|      Delhi|\n|  Karnataka|\n|  Telangana|\n|Maharashtra|\n| Tamil Nadu|\n|West Bengal|\n+-----------+\n\n"}], "source": "df.select('state').distinct().show()"}, {"cell_type": "code", "execution_count": 19, "id": "dfcebde9-ac2c-4b44-ba1c-785ade4518d1", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+-----------+-----+\n|      state|count|\n+-----------+-----+\n|    Gujarat| 2543|\n|      Delhi| 2578|\n|  Karnataka| 2483|\n|  Telangana| 2520|\n|Maharashtra| 2490|\n| Tamil Nadu| 2536|\n|West Bengal| 2503|\n+-----------+-----+\n\n"}], "source": "df.groupby('state').count().show()"}, {"cell_type": "code", "execution_count": 20, "id": "dc5ce53f-3ac8-41bf-9b7b-f3d97be2443d", "metadata": {"tags": []}, "outputs": [], "source": "#df.join"}, {"cell_type": "code", "execution_count": 21, "id": "ebc24406-4dc3-499d-86d9-e08bb9c58ffd", "metadata": {"tags": []}, "outputs": [], "source": "spark.stop()"}, {"cell_type": "code", "execution_count": null, "id": "48e90757-4eae-4a48-995c-3f46c69d73ee", "metadata": {}, "outputs": [], "source": ""}], "metadata": {"kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.11.8"}}, "nbformat": 4, "nbformat_minor": 5}